{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Using device: cpu\n",
      "[DEBUG] Loading dataset...\n",
      "[DEBUG] Original Train Size: 12,774,667\n",
      "[DEBUG] Train positive ratio: 0.4926433282597666\n",
      "[DEBUG] Val positive ratio: 0.5\n",
      "[DEBUG] Test positive ratio: 0.5\n",
      "[DEBUG] pos_weight for BCE: 1.03\n",
      "\n",
      "============================================================\n",
      "RUNNING WITH is_dendrite = False\n",
      "============================================================\n",
      "[DEBUG] Running BASELINE...\n",
      "[DEBUG] Parameter count: 4,545\n",
      "Epoch 1\n",
      "  Train Acc: 53.29%\n",
      "  Train Loss: 0.7071\n",
      "  Val Acc: 56.94%\n",
      "  Precision: 0.5533\n",
      "  Recall:    0.7208\n",
      "  F1 Score:  0.6260\n",
      "Epoch 2\n",
      "  Train Acc: 56.86%\n",
      "  Train Loss: 0.6861\n",
      "  Val Acc: 55.62%\n",
      "  Precision: 0.5353\n",
      "  Recall:    0.8530\n",
      "  F1 Score:  0.6578\n",
      "Epoch 3\n",
      "  Train Acc: 57.69%\n",
      "  Train Loss: 0.6845\n",
      "  Val Acc: 56.70%\n",
      "  Precision: 0.5469\n",
      "  Recall:    0.7823\n",
      "  F1 Score:  0.6437\n",
      "Epoch 4\n",
      "  Train Acc: 58.50%\n",
      "  Train Loss: 0.6806\n",
      "  Val Acc: 58.60%\n",
      "  Precision: 0.5872\n",
      "  Recall:    0.5790\n",
      "  F1 Score:  0.5831\n",
      "Epoch 5\n",
      "  Train Acc: 57.88%\n",
      "  Train Loss: 0.6819\n",
      "  Val Acc: 59.03%\n",
      "  Precision: 0.5761\n",
      "  Recall:    0.6843\n",
      "  F1 Score:  0.6255\n",
      "Epoch 6\n",
      "  Train Acc: 58.75%\n",
      "  Train Loss: 0.6783\n",
      "  Val Acc: 58.91%\n",
      "  Precision: 0.5724\n",
      "  Recall:    0.7049\n",
      "  F1 Score:  0.6318\n",
      "Epoch 7\n",
      "  Train Acc: 58.73%\n",
      "  Train Loss: 0.6790\n",
      "  Val Acc: 58.70%\n",
      "  Precision: 0.5860\n",
      "  Recall:    0.5925\n",
      "  F1 Score:  0.5892\n",
      "Epoch 8\n",
      "  Train Acc: 59.00%\n",
      "  Train Loss: 0.6778\n",
      "  Val Acc: 57.59%\n",
      "  Precision: 0.6034\n",
      "  Recall:    0.4431\n",
      "  F1 Score:  0.5109\n",
      "Epoch 9\n",
      "  Train Acc: 58.67%\n",
      "  Train Loss: 0.6781\n",
      "  Val Acc: 59.20%\n",
      "  Precision: 0.5817\n",
      "  Recall:    0.6555\n",
      "  F1 Score:  0.6164\n",
      "Epoch 10\n",
      "  Train Acc: 58.95%\n",
      "  Train Loss: 0.6773\n",
      "  Val Acc: 59.23%\n",
      "  Precision: 0.5942\n",
      "  Recall:    0.5819\n",
      "  F1 Score:  0.5880\n",
      "Epoch 11\n",
      "  Train Acc: 58.77%\n",
      "  Train Loss: 0.6772\n",
      "  Val Acc: 59.18%\n",
      "  Precision: 0.5666\n",
      "  Recall:    0.7814\n",
      "  F1 Score:  0.6568\n",
      "Epoch 12\n",
      "  Train Acc: 59.21%\n",
      "  Train Loss: 0.6746\n",
      "  Val Acc: 58.94%\n",
      "  Precision: 0.5840\n",
      "  Recall:    0.6213\n",
      "  F1 Score:  0.6021\n",
      "Epoch 13\n",
      "  Train Acc: 59.32%\n",
      "  Train Loss: 0.6737\n",
      "  Val Acc: 59.78%\n",
      "  Precision: 0.5824\n",
      "  Recall:    0.6910\n",
      "  F1 Score:  0.6321\n",
      "Epoch 14\n",
      "  Train Acc: 59.57%\n",
      "  Train Loss: 0.6728\n",
      "  Val Acc: 59.61%\n",
      "  Precision: 0.5904\n",
      "  Recall:    0.6276\n",
      "  F1 Score:  0.6084\n",
      "Epoch 15\n",
      "  Train Acc: 59.85%\n",
      "  Train Loss: 0.6725\n",
      "  Val Acc: 59.80%\n",
      "  Precision: 0.5922\n",
      "  Recall:    0.6295\n",
      "  F1 Score:  0.6103\n",
      "Epoch 16\n",
      "  Train Acc: 60.14%\n",
      "  Train Loss: 0.6703\n",
      "  Val Acc: 59.85%\n",
      "  Precision: 0.5899\n",
      "  Recall:    0.6463\n",
      "  F1 Score:  0.6168\n",
      "Epoch 17\n",
      "  Train Acc: 60.23%\n",
      "  Train Loss: 0.6696\n",
      "  Val Acc: 60.07%\n",
      "  Precision: 0.5941\n",
      "  Recall:    0.6358\n",
      "  F1 Score:  0.6142\n",
      "Epoch 18\n",
      "  Train Acc: 60.28%\n",
      "  Train Loss: 0.6695\n",
      "  Val Acc: 60.45%\n",
      "  Precision: 0.6153\n",
      "  Recall:    0.5579\n",
      "  F1 Score:  0.5852\n",
      "Epoch 19\n",
      "  Train Acc: 60.42%\n",
      "  Train Loss: 0.6687\n",
      "  Val Acc: 59.47%\n",
      "  Precision: 0.5677\n",
      "  Recall:    0.7943\n",
      "  F1 Score:  0.6621\n",
      "Epoch 20\n",
      "  Train Acc: 60.51%\n",
      "  Train Loss: 0.6682\n",
      "  Val Acc: 60.21%\n",
      "  Precision: 0.6039\n",
      "  Recall:    0.5935\n",
      "  F1 Score:  0.5986\n",
      "\n",
      "========== FINAL TEST ==========\n",
      "Test Acc: 61.03%\n",
      "Precision: 0.6115\n",
      "Recall:    0.6053\n",
      "F1 Score:  0.6084\n",
      "\n",
      "============================================================\n",
      "RUNNING WITH is_dendrite = True\n",
      "============================================================\n",
      "[DEBUG] Initializing WITH dendrites...\n",
      "Running Dendrite Experiment\n",
      "[DEBUG] Parameter count: 9,090\n",
      "Epoch 1\n",
      "  Train Acc: 55.49%\n",
      "  Train Loss: 0.6904\n",
      "  Val Acc: 58.94%\n",
      "  Precision: 0.5804\n",
      "  Recall:    0.6449\n",
      "  F1 Score:  0.6110\n",
      "Adding validation score 0.64488227\n",
      "Checking PAI switch with mode n, switch mode DOING_SWITCH_EVERY_TIME, epoch 0, last improved epoch 0, total epochs 0, n: 10, num_cycles: 0\n",
      "Returning True - switching every time\n",
      "Importing best Model for switch to PA...\n",
      "Switching back to N...\n",
      "Resetting committed to initial rate to False\n",
      "Saving model before starting normal training to retain PBNodes regardless of next N Phase results\n",
      "[DEBUG] Restructured Reset optimizer\n",
      "Epoch 2\n",
      "  Train Acc: 57.22%\n",
      "  Train Loss: 0.6860\n",
      "  Val Acc: 58.15%\n",
      "  Precision: 0.5888\n",
      "  Recall:    0.5401\n",
      "  F1 Score:  0.5634\n",
      "Adding validation score 0.54012494\n",
      "Checking PAI switch with mode n, switch mode DOING_SWITCH_EVERY_TIME, epoch 1, last improved epoch 1, total epochs 1, n: 10, num_cycles: 2\n",
      "Returning True - switching every time\n",
      "Importing best Model for switch to PA...\n",
      "Switching back to N...\n",
      "Resetting committed to initial rate to False\n",
      "Saving model before starting normal training to retain PBNodes regardless of next N Phase results\n",
      "[DEBUG] Restructured Reset optimizer\n",
      "Epoch 3\n",
      "  Train Acc: 58.24%\n",
      "  Train Loss: 0.6820\n",
      "  Val Acc: 57.16%\n",
      "  Precision: 0.5497\n",
      "  Recall:    0.7919\n",
      "  F1 Score:  0.6489\n",
      "Adding validation score 0.79192696\n",
      "Checking PAI switch with mode n, switch mode DOING_SWITCH_EVERY_TIME, epoch 2, last improved epoch 2, total epochs 2, n: 10, num_cycles: 4\n",
      "Returning True - switching every time\n",
      "Importing best Model for switch to PA...\n",
      "Switching back to N...\n",
      "Resetting committed to initial rate to False\n",
      "Saving model before starting normal training to retain PBNodes regardless of next N Phase results\n",
      "[DEBUG] Restructured Reset optimizer\n",
      "Epoch 4\n",
      "  Train Acc: 58.11%\n",
      "  Train Loss: 0.6816\n",
      "  Val Acc: 59.39%\n",
      "  Precision: 0.5768\n",
      "  Recall:    0.7054\n",
      "  F1 Score:  0.6347\n",
      "Adding validation score 0.70543008\n",
      "Checking PAI switch with mode n, switch mode DOING_SWITCH_EVERY_TIME, epoch 3, last improved epoch 3, total epochs 3, n: 10, num_cycles: 6\n",
      "Returning True - switching every time\n",
      "Importing best Model for switch to PA...\n",
      "Switching back to N...\n",
      "Resetting committed to initial rate to False\n",
      "Saving model before starting normal training to retain PBNodes regardless of next N Phase results\n",
      "[DEBUG] Restructured Reset optimizer\n",
      "Epoch 5\n",
      "  Train Acc: 58.55%\n",
      "  Train Loss: 0.6808\n",
      "  Val Acc: 58.82%\n",
      "  Precision: 0.5965\n",
      "  Recall:    0.5449\n",
      "  F1 Score:  0.5696\n",
      "Adding validation score 0.54493032\n",
      "Checking PAI switch with mode n, switch mode DOING_SWITCH_EVERY_TIME, epoch 4, last improved epoch 4, total epochs 4, n: 10, num_cycles: 8\n",
      "Returning True - switching every time\n",
      "Importing best Model for switch to PA...\n",
      "Switching back to N...\n",
      "Resetting committed to initial rate to False\n",
      "Saving model before starting normal training to retain PBNodes regardless of next N Phase results\n",
      "[DEBUG] Restructured Reset optimizer\n",
      "Epoch 6\n",
      "  Train Acc: 58.81%\n",
      "  Train Loss: 0.6789\n",
      "  Val Acc: 58.65%\n",
      "  Precision: 0.5616\n",
      "  Recall:    0.7886\n",
      "  F1 Score:  0.6560\n",
      "Adding validation score 0.78856319\n",
      "Checking PAI switch with mode n, switch mode DOING_SWITCH_EVERY_TIME, epoch 5, last improved epoch 5, total epochs 5, n: 10, num_cycles: 10\n",
      "Returning True - switching every time\n",
      "Importing best Model for switch to PA...\n",
      "Switching back to N...\n",
      "Resetting committed to initial rate to False\n",
      "Saving model before starting normal training to retain PBNodes regardless of next N Phase results\n",
      "[DEBUG] Restructured Reset optimizer\n",
      "Epoch 7\n",
      "  Train Acc: 59.19%\n",
      "  Train Loss: 0.6768\n",
      "  Val Acc: 59.61%\n",
      "  Precision: 0.5968\n",
      "  Recall:    0.5925\n",
      "  F1 Score:  0.5946\n",
      "Adding validation score 0.59250360\n",
      "Checking PAI switch with mode n, switch mode DOING_SWITCH_EVERY_TIME, epoch 6, last improved epoch 6, total epochs 6, n: 10, num_cycles: 12\n",
      "Returning True - switching every time\n",
      "Importing best Model for switch to PA...\n",
      "Switching back to N...\n",
      "Resetting committed to initial rate to False\n",
      "Saving model before starting normal training to retain PBNodes regardless of next N Phase results\n",
      "[DEBUG] Restructured Reset optimizer\n",
      "Epoch 8\n",
      "  Train Acc: 59.09%\n",
      "  Train Loss: 0.6765\n",
      "  Val Acc: 59.90%\n",
      "  Precision: 0.5758\n",
      "  Recall:    0.7520\n",
      "  F1 Score:  0.6522\n",
      "Adding validation score 0.75204229\n",
      "Checking PAI switch with mode n, switch mode DOING_SWITCH_EVERY_TIME, epoch 7, last improved epoch 7, total epochs 7, n: 10, num_cycles: 14\n",
      "Returning True - switching every time\n",
      "Importing best Model for switch to PA...\n",
      "Switching back to N...\n",
      "Resetting committed to initial rate to False\n",
      "Saving model before starting normal training to retain PBNodes regardless of next N Phase results\n",
      "[DEBUG] Restructured Reset optimizer\n",
      "Epoch 9\n",
      "  Train Acc: 59.40%\n",
      "  Train Loss: 0.6764\n",
      "  Val Acc: 59.92%\n",
      "  Precision: 0.5786\n",
      "  Recall:    0.7304\n",
      "  F1 Score:  0.6457\n",
      "Adding validation score 0.73041807\n",
      "Checking PAI switch with mode n, switch mode DOING_SWITCH_EVERY_TIME, epoch 8, last improved epoch 8, total epochs 8, n: 10, num_cycles: 16\n",
      "Returning True - switching every time\n",
      "Importing best Model for switch to PA...\n",
      "Switching back to N...\n",
      "Resetting committed to initial rate to False\n",
      "Saving model before starting normal training to retain PBNodes regardless of next N Phase results\n",
      "[DEBUG] Restructured Reset optimizer\n",
      "Epoch 10\n",
      "  Train Acc: 59.29%\n",
      "  Train Loss: 0.6744\n",
      "  Val Acc: 55.48%\n",
      "  Precision: 0.6203\n",
      "  Recall:    0.2826\n",
      "  F1 Score:  0.3882\n",
      "Adding validation score 0.28255646\n",
      "Checking PAI switch with mode n, switch mode DOING_SWITCH_EVERY_TIME, epoch 9, last improved epoch 9, total epochs 9, n: 10, num_cycles: 18\n",
      "Returning True - switching every time\n",
      "Importing best Model for switch to PA...\n",
      "Switching back to N...\n",
      "Resetting committed to initial rate to False\n",
      "Saving model before starting normal training to retain PBNodes regardless of next N Phase results\n",
      "[DEBUG] Restructured Reset optimizer\n",
      "Epoch 11\n",
      "  Train Acc: 59.98%\n",
      "  Train Loss: 0.6721\n",
      "  Val Acc: 60.98%\n",
      "  Precision: 0.5868\n",
      "  Recall:    0.7424\n",
      "  F1 Score:  0.6555\n",
      "Adding validation score 0.74243152\n",
      "Checking PAI switch with mode n, switch mode DOING_SWITCH_EVERY_TIME, epoch 10, last improved epoch 10, total epochs 10, n: 10, num_cycles: 20\n",
      "Returning True - switching every time\n",
      "Importing best Model for switch to PA...\n",
      "Switching back to N...\n",
      "Resetting committed to initial rate to False\n",
      "Saving model before starting normal training to retain PBNodes regardless of next N Phase results\n",
      "[DEBUG] Restructured Reset optimizer\n",
      "Epoch 12\n",
      "  Train Acc: 60.50%\n",
      "  Train Loss: 0.6699\n",
      "  Val Acc: 60.79%\n",
      "  Precision: 0.5992\n",
      "  Recall:    0.6516\n",
      "  F1 Score:  0.6243\n",
      "Adding validation score 0.65160980\n",
      "Checking PAI switch with mode n, switch mode DOING_SWITCH_EVERY_TIME, epoch 11, last improved epoch 11, total epochs 11, n: 10, num_cycles: 22\n",
      "Returning True - switching every time\n",
      "Importing best Model for switch to PA...\n",
      "Switching back to N...\n",
      "Resetting committed to initial rate to False\n",
      "Saving model before starting normal training to retain PBNodes regardless of next N Phase results\n",
      "[DEBUG] Restructured Reset optimizer\n",
      "Epoch 13\n",
      "  Train Acc: 60.52%\n",
      "  Train Loss: 0.6688\n",
      "  Val Acc: 60.79%\n",
      "  Precision: 0.5864\n",
      "  Recall:    0.7323\n",
      "  F1 Score:  0.6513\n",
      "Adding validation score 0.73234022\n",
      "Checking PAI switch with mode n, switch mode DOING_SWITCH_EVERY_TIME, epoch 12, last improved epoch 12, total epochs 12, n: 10, num_cycles: 24\n",
      "Returning True - switching every time\n",
      "Importing best Model for switch to PA...\n",
      "Switching back to N...\n",
      "Resetting committed to initial rate to False\n",
      "Saving model before starting normal training to retain PBNodes regardless of next N Phase results\n",
      "[DEBUG] Restructured Reset optimizer\n",
      "Epoch 14\n",
      "  Train Acc: 60.59%\n",
      "  Train Loss: 0.6677\n",
      "  Val Acc: 61.34%\n",
      "  Precision: 0.6002\n",
      "  Recall:    0.6795\n",
      "  F1 Score:  0.6374\n",
      "Adding validation score 0.67948102\n",
      "Checking PAI switch with mode n, switch mode DOING_SWITCH_EVERY_TIME, epoch 13, last improved epoch 13, total epochs 13, n: 10, num_cycles: 26\n",
      "Returning True - switching every time\n",
      "Importing best Model for switch to PA...\n",
      "Switching back to N...\n",
      "Resetting committed to initial rate to False\n",
      "Saving model before starting normal training to retain PBNodes regardless of next N Phase results\n",
      "[DEBUG] Restructured Reset optimizer\n",
      "Epoch 15\n",
      "  Train Acc: 60.87%\n",
      "  Train Loss: 0.6656\n",
      "  Val Acc: 61.29%\n",
      "  Precision: 0.5993\n",
      "  Recall:    0.6814\n",
      "  F1 Score:  0.6377\n",
      "Adding validation score 0.68140317\n",
      "Checking PAI switch with mode n, switch mode DOING_SWITCH_EVERY_TIME, epoch 14, last improved epoch 14, total epochs 14, n: 10, num_cycles: 28\n",
      "Returning True - switching every time\n",
      "Importing best Model for switch to PA...\n",
      "Switching back to N...\n",
      "Resetting committed to initial rate to False\n",
      "Saving model before starting normal training to retain PBNodes regardless of next N Phase results\n",
      "[DEBUG] Restructured Reset optimizer\n",
      "Epoch 16\n",
      "  Train Acc: 61.08%\n",
      "  Train Loss: 0.6648\n",
      "  Val Acc: 62.16%\n",
      "  Precision: 0.6059\n",
      "  Recall:    0.6958\n",
      "  F1 Score:  0.6477\n",
      "Adding validation score 0.69581932\n",
      "Checking PAI switch with mode n, switch mode DOING_SWITCH_EVERY_TIME, epoch 15, last improved epoch 15, total epochs 15, n: 10, num_cycles: 30\n",
      "Returning True - switching every time\n",
      "Importing best Model for switch to PA...\n",
      "Switching back to N...\n",
      "Resetting committed to initial rate to False\n",
      "Saving model before starting normal training to retain PBNodes regardless of next N Phase results\n",
      "[DEBUG] Restructured Reset optimizer\n",
      "Epoch 17\n",
      "  Train Acc: 61.77%\n",
      "  Train Loss: 0.6603\n",
      "  Val Acc: 61.53%\n",
      "  Precision: 0.5875\n",
      "  Recall:    0.7746\n",
      "  F1 Score:  0.6682\n",
      "Adding validation score 0.77462758\n",
      "Checking PAI switch with mode n, switch mode DOING_SWITCH_EVERY_TIME, epoch 16, last improved epoch 16, total epochs 16, n: 10, num_cycles: 32\n",
      "Returning True - switching every time\n",
      "Importing best Model for switch to PA...\n",
      "Switching back to N...\n",
      "Resetting committed to initial rate to False\n",
      "Saving model before starting normal training to retain PBNodes regardless of next N Phase results\n",
      "[DEBUG] Restructured Reset optimizer\n",
      "Epoch 18\n",
      "  Train Acc: 62.03%\n",
      "  Train Loss: 0.6591\n",
      "  Val Acc: 62.90%\n",
      "  Precision: 0.6213\n",
      "  Recall:    0.6607\n",
      "  F1 Score:  0.6404\n",
      "Adding validation score 0.66074003\n",
      "Checking PAI switch with mode n, switch mode DOING_SWITCH_EVERY_TIME, epoch 17, last improved epoch 17, total epochs 17, n: 10, num_cycles: 34\n",
      "Returning True - switching every time\n",
      "Importing best Model for switch to PA...\n",
      "Switching back to N...\n",
      "Resetting committed to initial rate to False\n",
      "Saving model before starting normal training to retain PBNodes regardless of next N Phase results\n",
      "[DEBUG] Restructured Reset optimizer\n",
      "Epoch 19\n",
      "  Train Acc: 62.48%\n",
      "  Train Loss: 0.6570\n",
      "  Val Acc: 62.76%\n",
      "  Precision: 0.6101\n",
      "  Recall:    0.7069\n",
      "  F1 Score:  0.6549\n",
      "Adding validation score 0.70687170\n",
      "Checking PAI switch with mode n, switch mode DOING_SWITCH_EVERY_TIME, epoch 18, last improved epoch 18, total epochs 18, n: 10, num_cycles: 36\n",
      "Returning True - switching every time\n",
      "Importing best Model for switch to PA...\n",
      "Switching back to N...\n",
      "Resetting committed to initial rate to False\n",
      "Saving model before starting normal training to retain PBNodes regardless of next N Phase results\n",
      "[DEBUG] Restructured Reset optimizer\n",
      "Epoch 20\n",
      "  Train Acc: 61.97%\n",
      "  Train Loss: 0.6567\n",
      "  Val Acc: 63.72%\n",
      "  Precision: 0.6132\n",
      "  Recall:    0.7429\n",
      "  F1 Score:  0.6719\n",
      "Adding validation score 0.74291206\n",
      "Checking PAI switch with mode n, switch mode DOING_SWITCH_EVERY_TIME, epoch 19, last improved epoch 19, total epochs 19, n: 10, num_cycles: 38\n",
      "Returning True - switching every time\n",
      "Importing best Model for switch to PA...\n",
      "Switching back to N...\n",
      "Resetting committed to initial rate to False\n",
      "Saving model before starting normal training to retain PBNodes regardless of next N Phase results\n",
      "[DEBUG] Restructured Reset optimizer\n",
      "\n",
      "========== FINAL TEST ==========\n",
      "Test Acc: 63.25%\n",
      "Precision: 0.6062\n",
      "Recall:    0.7558\n",
      "F1 Score:  0.6728\n",
      "Total dendrites added: 20\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "from perforatedai import globals_perforatedai as GPA\n",
    "from perforatedai import utils_perforatedai as UPA\n",
    "\n",
    "# ==========================================================\n",
    "# CONFIG\n",
    "# ==========================================================\n",
    "\n",
    "DATA_PATH = \"../data/processed/modis_firms_train_val_test_dataset.npz\"\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "TEST_BATCH_SIZE = 512\n",
    "EPOCHS = 20\n",
    "LR = 0.001\n",
    "WEIGHT_DECAY = 0.0\n",
    "GAMMA = 0.95\n",
    "\n",
    "MAX_TRAIN = 20000\n",
    "MAX_VAL = 5000\n",
    "MAX_TEST = 5000\n",
    "\n",
    "device = \"cpu\"\n",
    "print(f\"[DEBUG] Using device: {device}\")\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# ==========================================================\n",
    "# MODEL\n",
    "# ==========================================================\n",
    "\n",
    "class FireNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=64):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)  \n",
    "        return x\n",
    "\n",
    "# ==========================================================\n",
    "# LOAD DATA\n",
    "# ==========================================================\n",
    "\n",
    "print(\"[DEBUG] Loading dataset...\")\n",
    "\n",
    "with np.load(DATA_PATH) as f:\n",
    "    X_train = f[\"X_train\"]\n",
    "    y_train = f[\"y_train\"]\n",
    "    X_val = f[\"X_val\"]\n",
    "    y_val = f[\"y_val\"]\n",
    "    X_test = f[\"X_test\"]\n",
    "    y_test = f[\"y_test\"]\n",
    "\n",
    "print(f\"[DEBUG] Original Train Size: {len(X_train):,}\")\n",
    "\n",
    "# ==========================================================\n",
    "# BALANCE TRAINING DATA ONLY\n",
    "# ==========================================================\n",
    "\n",
    "def balanced_sample(X, y, max_samples):\n",
    "    pos_idx = np.where(y == 1)[0]\n",
    "    neg_idx = np.where(y == 0)[0]\n",
    "\n",
    "    n_each = max_samples // 2\n",
    "    n_each = min(n_each, len(pos_idx), len(neg_idx))\n",
    "\n",
    "    pos_sample = np.random.choice(pos_idx, n_each, replace=False)\n",
    "    neg_sample = np.random.choice(neg_idx, n_each, replace=False)\n",
    "\n",
    "    idx = np.concatenate([pos_sample, neg_sample])\n",
    "    np.random.shuffle(idx)\n",
    "\n",
    "    return X[idx], y[idx]\n",
    "\n",
    "def subsample_training(X, y, max_negatives=400_000):\n",
    "    \"\"\"Keep all positives, subsample negatives to max_negatives\"\"\"\n",
    "    pos_idx = np.where(y == 1)[0]\n",
    "    neg_idx = np.where(y == 0)[0]\n",
    "    np.random.shuffle(neg_idx)\n",
    "    neg_idx_sub = neg_idx[:max_negatives]\n",
    "\n",
    "    idx = np.concatenate([pos_idx, neg_idx_sub])\n",
    "    np.random.shuffle(idx)\n",
    "\n",
    "    return X[idx], y[idx]\n",
    "\n",
    "X_train, y_train = subsample_training(X_train, y_train, max_negatives=MAX_TRAIN//2)\n",
    "\n",
    "# Keep validation and test balanced\n",
    "X_val, y_val = balanced_sample(X_val, y_val, MAX_VAL)\n",
    "X_test, y_test = balanced_sample(X_test, y_test, MAX_TEST)\n",
    "\n",
    "print(\"[DEBUG] Train positive ratio:\", np.mean(y_train))\n",
    "print(\"[DEBUG] Val positive ratio:\", np.mean(y_val))\n",
    "print(\"[DEBUG] Test positive ratio:\", np.mean(y_test))\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# DATALOADERS\n",
    "# ==========================================================\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    TensorDataset(torch.tensor(X_train).float(),\n",
    "                torch.tensor(y_train).float()),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    TensorDataset(torch.tensor(X_val).float(),\n",
    "                torch.tensor(y_val).float()),\n",
    "    batch_size=TEST_BATCH_SIZE\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    TensorDataset(torch.tensor(X_test).float(),\n",
    "                torch.tensor(y_test).float()),\n",
    "    batch_size=TEST_BATCH_SIZE\n",
    ")\n",
    "\n",
    "# ==========================================================\n",
    "# LOSS FUNCTION WITH DYNAMIC pos_weight\n",
    "# ==========================================================\n",
    "\n",
    "pos_count = np.sum(y_train)\n",
    "neg_count = len(y_train) - pos_count\n",
    "pos_weight_tensor = torch.tensor([neg_count / pos_count], dtype=torch.float32).to(device)\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight_tensor)\n",
    "print(f\"[DEBUG] pos_weight for BCE: {pos_weight_tensor.item():.2f}\")\n",
    "\n",
    "# ==========================================================\n",
    "# TRAIN / EVAL\n",
    "# ==========================================================\n",
    "\n",
    "def train_epoch():\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    total_loss = 0\n",
    "\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(data)\n",
    "\n",
    "        loss = loss_fn(output, target.unsqueeze(1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # logits threshold at 0\n",
    "        preds = (output > 0).float()\n",
    "        correct += preds.eq(target.unsqueeze(1)).sum().item()\n",
    "\n",
    "    acc = 100.0 * correct / len(train_loader.dataset)\n",
    "    return acc, total_loss / len(train_loader)\n",
    "\n",
    "\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data = data.to(device)\n",
    "            output = model(data)\n",
    "\n",
    "            # threshold logits at 0\n",
    "            preds = (output > 0).cpu().numpy().flatten()\n",
    "\n",
    "            all_preds.extend(preds)\n",
    "            all_targets.extend(target.numpy())\n",
    "\n",
    "    acc = np.mean(np.array(all_preds) == np.array(all_targets))\n",
    "    precision = precision_score(all_targets, all_preds, zero_division=0)\n",
    "    recall = recall_score(all_targets, all_preds, zero_division=0)\n",
    "    f1 = f1_score(all_targets, all_preds, zero_division=0)\n",
    "\n",
    "    return acc * 100, precision, recall, f1\n",
    "\n",
    "# ==========================================================\n",
    "# RUN EXPERIMENTS\n",
    "# ==========================================================\n",
    "\n",
    "for is_dendrite in [False, True]:\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"RUNNING WITH is_dendrite = {is_dendrite}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    input_dim = X_train.shape[1]\n",
    "    base_model = FireNN(input_dim)\n",
    "\n",
    "    if is_dendrite:\n",
    "        print(\"[DEBUG] Initializing WITH dendrites...\")\n",
    "        # model = UPA.initialize_pai(base_model, save_name=\"fire_model\")\n",
    "\n",
    "        GPA.pc.set_testing_dendrite_capacity(False)\n",
    "        GPA.pc.set_weight_decay_accepted(True)\n",
    "        GPA.pc.set_verbose(False)\n",
    "        \n",
    "        model = UPA.initialize_pai(base_model, save_name=\"fire_model\")\n",
    "\n",
    "        GPA.pai_tracker.set_optimizer(optim.Adam)\n",
    "        GPA.pai_tracker.set_scheduler(StepLR)\n",
    "    else:\n",
    "        print(\"[DEBUG] Running BASELINE...\")\n",
    "        model = base_model\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    print(f\"[DEBUG] Parameter count: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "    if is_dendrite:\n",
    "        optim_args = {\"params\": model.parameters(), \"lr\": LR, \"weight_decay\": WEIGHT_DECAY}\n",
    "        sched_args = {\"step_size\": 1, \"gamma\": GAMMA}\n",
    "        optimizer, scheduler = GPA.pai_tracker.setup_optimizer(model, optim_args, sched_args)\n",
    "    else:\n",
    "        optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "        scheduler = StepLR(optimizer, step_size=1, gamma=GAMMA)\n",
    "\n",
    "    # ---------------- TRAIN ----------------\n",
    "\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "\n",
    "        train_acc, train_loss = train_epoch()\n",
    "        scheduler.step()\n",
    "        val_acc, val_prec, val_rec, val_f1 = evaluate(val_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch}\")\n",
    "        print(f\"  Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"  Train Loss: {train_loss:.4f}\")\n",
    "        print(f\"  Val Acc: {val_acc:.2f}%\")\n",
    "        print(f\"  Precision: {val_prec:.4f}\")\n",
    "        print(f\"  Recall:    {val_rec:.4f}\")\n",
    "        print(f\"  F1 Score:  {val_f1:.4f}\")\n",
    "\n",
    "        if is_dendrite:\n",
    "            model, restructured, training_complete = \\\n",
    "                GPA.pai_tracker.add_validation_score(val_rec, model)\n",
    "\n",
    "            if restructured and not training_complete:\n",
    "                print(\"[DEBUG] Restructured Reset optimizer\")\n",
    "                optim_args = {\"params\": model.parameters(), \"lr\": LR, \"weight_decay\": WEIGHT_DECAY}\n",
    "                sched_args = {\"step_size\": 1, \"gamma\": GAMMA}\n",
    "                optimizer, scheduler = GPA.pai_tracker.setup_optimizer(model, optim_args, sched_args)\n",
    "\n",
    "            if training_complete:\n",
    "                print(\"[DEBUG] Training ended early by PAI.\")\n",
    "                break\n",
    "\n",
    "\n",
    "    # ---------------- TEST ----------------\n",
    "\n",
    "    test_acc, test_prec, test_rec, test_f1 = evaluate(test_loader)\n",
    "\n",
    "    print(\"\\n========== FINAL TEST ==========\")\n",
    "    print(f\"Test Acc: {test_acc:.2f}%\")\n",
    "    print(f\"Precision: {test_prec:.4f}\")\n",
    "    print(f\"Recall:    {test_rec:.4f}\")\n",
    "    print(f\"F1 Score:  {test_f1:.4f}\")\n",
    "\n",
    "    if is_dendrite:\n",
    "        print(\"Total dendrites added:\",\n",
    "            GPA.pai_tracker.member_vars[\"num_dendrites_added\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
